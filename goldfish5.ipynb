{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elodie0778/pirhana/blob/main/goldfish5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBGTNFZjdn5D",
        "outputId": "b08fad16-f9f3-4e71-b211-1d7a0871ca17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# %% [markdown]\n",
        "# # 1. Mount Google Drive\n",
        "#\n",
        "# Mount Google Drive to access and save data persistently.\n",
        "\n",
        "# %%\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFLxChhldpIX",
        "outputId": "fbd46f0f-46a5-4afe-defe-15e0b6046fff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.1.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting ta\n",
            "  Downloading ta-0.11.0.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.14.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.36)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.6)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from ta) (2.2.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.8.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.13.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.17.0)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.8-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->ta) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->ta) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->ta) (2024.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.2.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (9.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "Downloading optuna-4.1.0-py3-none-any.whl (364 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m364.4/364.4 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.14.0-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.5/233.5 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading Mako-1.3.8-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: ta\n",
            "  Building wheel for ta (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ta: filename=ta-0.11.0-py3-none-any.whl size=29412 sha256=f92cc6ae65d9a8cf30b740ebe41da00e2660dced06368985c6bcdeb309f6bbcb\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/67/4f/8a9f252836e053e532c6587a3230bc72a4deb16b03a829610b\n",
            "Successfully built ta\n",
            "Installing collected packages: Mako, colorlog, alembic, ta, optuna, catboost\n",
            "Successfully installed Mako-1.3.8 alembic-1.14.0 catboost-1.2.7 colorlog-6.9.0 optuna-4.1.0 ta-0.11.0\n",
            "Collecting optuna-integration\n",
            "  Downloading optuna_integration-4.1.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (from optuna-integration) (4.1.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna->optuna-integration) (1.14.0)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna->optuna-integration) (6.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna->optuna-integration) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna->optuna-integration) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from optuna->optuna-integration) (2.0.36)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna->optuna-integration) (4.66.6)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna->optuna-integration) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna->optuna-integration) (1.3.8)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna->optuna-integration) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.4.2->optuna->optuna-integration) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna->optuna-integration) (3.0.2)\n",
            "Downloading optuna_integration-4.1.0-py3-none-any.whl (97 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.4/97.4 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: optuna-integration\n",
            "Successfully installed optuna-integration-4.1.0\n"
          ]
        }
      ],
      "source": [
        "# %% [markdown]\n",
        "# # 2. Install Necessary Libraries\n",
        "#\n",
        "# Install and upgrade necessary libraries. Some libraries might already be installed in Google Colab, but specifying them ensures compatibility.\n",
        "\n",
        "# %%\n",
        "# Install necessary libraries\n",
        "!pip install --upgrade optuna ta catboost\n",
        "!pip install optuna-integration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "oLqdtYrjaHzh"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Machine Learning Libraries\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# For Technical Indicators\n",
        "import ta\n",
        "\n",
        "# For Optuna Hyperparameter Tuning\n",
        "import optuna\n",
        "from optuna.pruners import MedianPruner\n",
        "from optuna.exceptions import TrialPruned\n",
        "\n",
        "# For CatBoost\n",
        "from catboost import CatBoostRegressor, Pool, cv as catboost_cv\n",
        "\n",
        "# For Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# For saving/loading data\n",
        "import pickle\n",
        "\n",
        "# Suppress warnings for cleaner output\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3ao1yVXndsPj"
      },
      "outputs": [],
      "source": [
        "# %% [markdown]\n",
        "# # 3. Import Libraries\n",
        "#\n",
        "# Import all necessary libraries for data processing, model training, evaluation, and visualization.\n",
        "\n",
        "# %%\n",
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Machine Learning Libraries\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# For Technical Indicators\n",
        "import ta\n",
        "\n",
        "# For Optuna Hyperparameter Tuning\n",
        "import optuna\n",
        "from optuna.pruners import MedianPruner\n",
        "from optuna.exceptions import TrialPruned\n",
        "\n",
        "# For CatBoost\n",
        "from catboost import CatBoostRegressor, Pool, cv as catboost_cv\n",
        "\n",
        "# For Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# For saving/loading data\n",
        "import pickle\n",
        "\n",
        "# Suppress warnings for cleaner output\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LaasCwYjdubK"
      },
      "outputs": [],
      "source": [
        "# %% [markdown]\n",
        "# # 4. Define Paths and Initialize Directories\n",
        "#\n",
        "# Define file paths for data storage and ensure necessary directories exist.\n",
        "\n",
        "# %%\n",
        "# Define paths\n",
        "DATA_PATH = '/content/drive/MyDrive/data3/'\n",
        "STUDIES_DIR = os.path.join(DATA_PATH, 'optuna_studies3')\n",
        "FORECASTS_PATH = os.path.join(DATA_PATH, 'stock_forecasts3.pkl')\n",
        "PERFORMANCE_PATH = os.path.join(DATA_PATH, 'model_performance3.pkl')\n",
        "BEST_PARAMS_PATH = os.path.join(DATA_PATH, 'best_params_dict3.pkl')\n",
        "FINAL_RANKINGS_PATH = '/content/drive/MyDrive/final_stock_rankings3.csv'\n",
        "\n",
        "# Create necessary directories if they don't exist\n",
        "os.makedirs(STUDIES_DIR, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rUJCd6wd4cZ",
        "outputId": "122f6156-730c-4995-8893-3365a928f211"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded existing best parameters.\n",
            "Loaded existing forecasts.\n",
            "Loaded existing model performance data.\n"
          ]
        }
      ],
      "source": [
        "# %% [markdown]\n",
        "# # 5. Load Existing Data\n",
        "#\n",
        "# Load existing best parameters, forecasts, and model performance data if available. This ensures continuity in your workflow.\n",
        "\n",
        "# %%\n",
        "# Load existing best parameters if available\n",
        "if os.path.exists(BEST_PARAMS_PATH):\n",
        "    with open(BEST_PARAMS_PATH, 'rb') as f:\n",
        "        best_params_dict = pickle.load(f)\n",
        "    print(\"Loaded existing best parameters.\")\n",
        "else:\n",
        "    best_params_dict = {}\n",
        "    print(\"No existing best parameters found. Starting fresh.\")\n",
        "\n",
        "# Load existing forecasts if available\n",
        "if os.path.exists(FORECASTS_PATH):\n",
        "    with open(FORECASTS_PATH, 'rb') as f:\n",
        "        stock_forecasts = pickle.load(f)\n",
        "    print(\"Loaded existing forecasts.\")\n",
        "else:\n",
        "    stock_forecasts = {}\n",
        "    print(\"No existing forecasts found. Starting fresh.\")\n",
        "\n",
        "# Load existing model performance data if available\n",
        "if os.path.exists(PERFORMANCE_PATH):\n",
        "    with open(PERFORMANCE_PATH, 'rb') as f:\n",
        "        model_performance = pickle.load(f)\n",
        "    print(\"Loaded existing model performance data.\")\n",
        "else:\n",
        "    model_performance = []\n",
        "    print(\"No existing model performance data found. Starting fresh.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MebRUgxjd7Ct",
        "outputId": "5f2e8cf9-8905-4bbc-a90b-8bf54b3ddc77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total CSV files found: 282\n",
            "Loaded final_stock_rankings3.csv.\n",
            "Number of valid tickers with FinalScore: 210\n",
            "Total stocks loaded after filtering: 210\n"
          ]
        }
      ],
      "source": [
        "# %% [markdown]\n",
        "# # 6. Load and Preprocess Stock Data\n",
        "#\n",
        "# Load all cleaned stock CSV files from the `data3` folder, merge them with `FinalScore` from `final_stock_rankings3.csv`, and discard any stocks that do not have a `FinalScore`.\n",
        "\n",
        "# %%\n",
        "# List all CSV files in the directory matching '*_data.csv'\n",
        "csv_files = glob.glob(os.path.join(DATA_PATH, '*_data.csv'))\n",
        "\n",
        "print(f\"Total CSV files found: {len(csv_files)}\")\n",
        "\n",
        "# Load FinalScore data\n",
        "if os.path.exists(FINAL_RANKINGS_PATH):\n",
        "    final_rankings = pd.read_csv(FINAL_RANKINGS_PATH)\n",
        "    print(\"Loaded final_stock_rankings3.csv.\")\n",
        "else:\n",
        "    raise FileNotFoundError(\"final_stock_rankings3.csv not found in the data3 folder.\")\n",
        "\n",
        "# Keep only 'Ticker' and 'FinalScore'\n",
        "final_rankings = final_rankings[['Ticker', 'FinalScore']].dropna()\n",
        "final_rankings = final_rankings.drop_duplicates(subset='Ticker')\n",
        "\n",
        "# List of tickers with FinalScore\n",
        "valid_tickers = set(final_rankings['Ticker'].unique())\n",
        "\n",
        "print(f\"Number of valid tickers with FinalScore: {len(valid_tickers)}\")\n",
        "\n",
        "# Initialize a dictionary to store DataFrames\n",
        "stock_data = {}\n",
        "\n",
        "# Feature Engineering Function\n",
        "def add_technical_indicators(df):\n",
        "    df = df.copy()\n",
        "    # Since the new data includes various price metrics, additional technical indicators can be minimal\n",
        "    # However, if needed, you can add more indicators here\n",
        "    df.dropna(inplace=True)\n",
        "    return df\n",
        "\n",
        "# Load and preprocess each CSV file\n",
        "for file in csv_files:\n",
        "    ticker = os.path.basename(file).split('_')[0]\n",
        "    # Only consider tickers that appear in final_rankings\n",
        "    if ticker not in valid_tickers:\n",
        "        continue\n",
        "    df = pd.read_csv(file)\n",
        "    df['Date'] = pd.to_datetime(df['Date'])\n",
        "    df = df.sort_values('Date')\n",
        "    df = add_technical_indicators(df)\n",
        "    df.reset_index(drop=True, inplace=True)\n",
        "    stock_data[ticker] = df\n",
        "\n",
        "print(f\"Total stocks loaded after filtering: {len(stock_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiKYfzlrd9kT",
        "outputId": "080492f2-1d0d-4d49-8d31-9bacdc11f810"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total samples after combining all stocks: 754600\n"
          ]
        }
      ],
      "source": [
        "# %% [markdown]\n",
        "# # 7. Merge FinalScore and Additional Preprocessing\n",
        "#\n",
        "# Assign the `FinalScore` to each stock's DataFrame and prepare the data for modeling by defining features and the target variable.\n",
        "\n",
        "# %%\n",
        "# Initialize a dictionary to store FinalScore for each stock\n",
        "final_score_dict = final_rankings.set_index('Ticker')['FinalScore'].to_dict()\n",
        "\n",
        "# Assign FinalScore to each stock's DataFrame\n",
        "for ticker, df in stock_data.items():\n",
        "    df['FinalScore'] = final_score_dict.get(ticker, 0)  # Assign 0 if not found, though all tickers should have FinalScore\n",
        "    stock_data[ticker] = df\n",
        "\n",
        "# Feature Engineering and Target Definition\n",
        "feature_cols = ['Market_Cap_EBT_Excl_Unusual_Items', 'Market_Cap_Total_Revenue',\n",
        "               'Market_Cap_Book_Value', 'Price_Last_Quarter_Levered_FCF',\n",
        "               'Price_Funds_From_Operations', 'Price_Tangible_Book',\n",
        "               'TEV_Excl_Opp_Leases_Total_Revenue', 'TEV_Employees',\n",
        "               'Price_Last Quarter_EPS(SNL)', 'Price_Last_Quarter_Net_FCF(SNL)',\n",
        "               'Price_Sales(SNL)', 'Price_Adj_Funds_From_Opperations',\n",
        "               'Price_Forward_EPS', 'PEG_Ratio',\n",
        "               'Market_Cap_Forward_Total_Revenue',\n",
        "               'Diluted_Market_Cap_Outstanding_Forward_Total_Revenue',\n",
        "               'Diluted_Market_Cap_Exercisable_Forward_Total_Revenue',\n",
        "               'Short_Interest_Ratio', 'Day_Open_Price', 'Day_Close_Price',\n",
        "               'Day_High_Price', 'Day_Low_Price', 'VWAP',\n",
        "               'Shares_Outstanding', 'Volume', 'FinalScore']\n",
        "\n",
        "# Define prediction horizon (30 days ahead)\n",
        "TARGET_WINDOW_DAYS = 30\n",
        "\n",
        "# Initialize lists to store features, targets, and sample weights\n",
        "X_list = []\n",
        "y_list = []\n",
        "sample_weights = []\n",
        "\n",
        "# Iterate through each stock to prepare data\n",
        "for ticker, df in stock_data.items():\n",
        "    if len(df) < (TARGET_WINDOW_DAYS + 1):\n",
        "        continue  # Skip stocks with insufficient data\n",
        "\n",
        "    # Create target variable: percentage return over the next TARGET_WINDOW_DAYS\n",
        "    df['Future_Close'] = df['Day_Close_Price'].shift(-TARGET_WINDOW_DAYS)\n",
        "    df['Target_Return'] = ((df['Future_Close'] - df['Day_Close_Price']) / df['Day_Close_Price']) * 100\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "    # Features and target\n",
        "    X = df[feature_cols].values\n",
        "    y = df['Target_Return'].values\n",
        "\n",
        "    # Assign weights: higher weight for higher FinalScore\n",
        "    # Normalize FinalScore to [0.5, 1.5] for weighting purposes\n",
        "    score = df['FinalScore'].iloc[0]  # Assuming FinalScore is constant per stock\n",
        "    max_score = final_rankings['FinalScore'].max()\n",
        "    weight = 1 + (score / max_score)  # Adjust as needed\n",
        "\n",
        "    weights = np.full_like(y, weight, dtype=np.float32)\n",
        "\n",
        "    X_list.append(X)\n",
        "    y_list.append(y)\n",
        "    sample_weights.append(weights)\n",
        "\n",
        "# Combine all stocks' data\n",
        "X = np.vstack(X_list)\n",
        "y = np.hstack(y_list)\n",
        "sample_weights = np.hstack(sample_weights)\n",
        "\n",
        "print(f\"Total samples after combining all stocks: {X.shape[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "LKS_xjVJeCRd"
      },
      "outputs": [],
      "source": [
        "# %% [markdown]\n",
        "# # 8. Define Helper Functions\n",
        "#\n",
        "# Define functions to check the existence of Optuna studies and to allocate investments based on expected profits.\n",
        "\n",
        "# %%\n",
        "# Function to determine if a study exists\n",
        "def study_exists(study_name, storage_name):\n",
        "    from optuna.storages import RDBStorage\n",
        "    try:\n",
        "        storage = RDBStorage(url=storage_name)\n",
        "        storage.get_study_id_from_name(study_name)\n",
        "        return True\n",
        "    except KeyError:\n",
        "        return False\n",
        "\n",
        "# Function to allocate investment to the top-performing stock\n",
        "def allocate_investment(profit_df, total_investment=30):\n",
        "    \"\"\"\n",
        "    Allocates the total investment to the stock with the highest expected profit.\n",
        "\n",
        "    Parameters:\n",
        "    - profit_df (pd.DataFrame): DataFrame containing 'Stock', 'Expected_Profit'.\n",
        "    - total_investment (float): Total amount to invest.\n",
        "\n",
        "    Returns:\n",
        "    - allocation (dict): Dictionary with 'Stock', 'Investment', 'Expected_Profit'.\n",
        "    - total_profit (float): Total expected profit from the investment.\n",
        "    \"\"\"\n",
        "    if profit_df.empty:\n",
        "        print(\"No adequate stocks available for investment.\")\n",
        "        return None, 0.0\n",
        "\n",
        "    # Sort the DataFrame by Expected Profit in descending order (higher is better)\n",
        "    sorted_df = profit_df.sort_values(by='Expected_Profit', ascending=False).reset_index(drop=True)\n",
        "\n",
        "    # Select the top stock\n",
        "    top_stock = sorted_df.iloc[0]\n",
        "\n",
        "    # Allocate the entire investment to the top stock\n",
        "    allocation = {\n",
        "        'Stock': top_stock['Stock'],\n",
        "        'Investment': round(total_investment, 2),\n",
        "        'Expected_Profit': round(top_stock['Expected_Profit'], 2)\n",
        "    }\n",
        "\n",
        "    # Total profit is the expected profit from the top stock\n",
        "    total_profit = allocation['Expected_Profit']\n",
        "\n",
        "    return allocation, total_profit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbHT8zhtjBpQ",
        "outputId": "1e03f662-09de-4663-c24e-93e725cbb185"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed stock: ANET\n",
            "Processed stock: AXON\n",
            "Processed stock: ANSS\n",
            "Processed stock: AVGO\n",
            "Processed stock: AMZN\n",
            "Processed stock: AON\n",
            "Processed stock: APD\n",
            "Processed stock: AMGN\n",
            "Processed stock: AMD\n",
            "Processed stock: AMP\n",
            "Processed stock: AKAM\n",
            "Processed stock: AMAT\n",
            "Processed stock: ALNY\n",
            "Processed stock: ADP\n",
            "Processed stock: AJG\n",
            "Processed stock: AIZ\n",
            "Processed stock: ADSK\n",
            "Processed stock: A\n",
            "Processed stock: ADBE\n",
            "Processed stock: ADI\n",
            "Processed stock: AXP\n",
            "Processed stock: AAPL\n",
            "Processed stock: ACGL\n",
            "Processed stock: ABBV\n",
            "Processed stock: BKNG\n",
            "Processed stock: BK\n",
            "Processed stock: BR\n",
            "Processed stock: BAC\n",
            "Processed stock: BKR\n",
            "Processed stock: BLK\n",
            "Processed stock: BXP\n",
            "Processed stock: BBY\n",
            "Processed stock: CRM\n",
            "Processed stock: CRH\n",
            "Processed stock: CSCO\n",
            "Processed stock: CPRT\n",
            "Processed stock: COR\n",
            "Processed stock: COP\n",
            "Processed stock: COST\n",
            "Processed stock: CPB\n",
            "Processed stock: CNH\n",
            "Processed stock: COO\n",
            "Processed stock: CMS\n",
            "Processed stock: COF\n",
            "Processed stock: CMI\n",
            "Processed stock: CI\n",
            "Processed stock: CMCSA\n",
            "Processed stock: CLX\n",
            "Processed stock: CMG\n",
            "Processed stock: CHRW\n",
            "Processed stock: CBRE\n",
            "Processed stock: CAT\n",
            "Processed stock: CAH\n",
            "Processed stock: CDNS\n",
            "Processed stock: CVX\n",
            "Processed stock: C\n",
            "Processed stock: FICO\n",
            "Processed stock: FIS\n",
            "Processed stock: FERG\n",
            "Processed stock: EXC\n",
            "Processed stock: FI\n",
            "Processed stock: FDX\n",
            "Processed stock: FBIN\n",
            "Processed stock: EQT\n",
            "Processed stock: FDS\n",
            "Processed stock: EXPD\n",
            "Processed stock: FANG\n",
            "Processed stock: ETN\n",
            "Processed stock: ES\n",
            "Processed stock: EIX\n",
            "Processed stock: EQIX\n",
            "Processed stock: EME\n",
            "Processed stock: ELV\n",
            "Processed stock: DXCM\n",
            "Processed stock: EA\n",
            "Processed stock: DHR\n",
            "Processed stock: DGX\n",
            "Processed stock: DIS\n",
            "Processed stock: DLR\n",
            "Processed stock: ECL\n",
            "Processed stock: FTV\n",
            "Processed stock: DAL\n",
            "Processed stock: DE\n",
            "Processed stock: DFS\n",
            "Processed stock: IEX\n",
            "Processed stock: INTC\n",
            "Processed stock: ISRG\n",
            "Processed stock: IRM\n",
            "Processed stock: HUM\n",
            "Processed stock: IQV\n",
            "Processed stock: IP\n",
            "Processed stock: INTU\n",
            "Processed stock: IDXX\n",
            "Processed stock: HUBB\n",
            "Processed stock: HPE\n",
            "Processed stock: IBM\n",
            "Processed stock: HON\n",
            "Processed stock: HOLX\n",
            "Processed stock: HES\n",
            "Processed stock: HBAN\n",
            "Processed stock: HIG\n",
            "Processed stock: HD\n",
            "Processed stock: HCA\n",
            "Processed stock: GS\n",
            "Processed stock: GWW\n",
            "Processed stock: GOOGL\n",
            "Processed stock: GE\n",
            "Processed stock: GDDY\n",
            "Processed stock: IT\n",
            "Processed stock: KR\n",
            "Processed stock: LDOS\n",
            "Processed stock: LRCX\n",
            "Processed stock: LLY\n",
            "Processed stock: LII\n",
            "Processed stock: LH\n",
            "Processed stock: JNPR\n",
            "Processed stock: LNG\n",
            "Processed stock: LOW\n",
            "Processed stock: KHC\n",
            "Processed stock: JPM\n",
            "Processed stock: KEYS\n",
            "Processed stock: LULU\n",
            "Processed stock: KMI\n",
            "Processed stock: KMB\n",
            "Processed stock: KKR\n",
            "Processed stock: KMX\n",
            "Processed stock: JBHT\n",
            "Processed stock: J\n",
            "Processed stock: NFLX\n",
            "Processed stock: NOC\n",
            "Processed stock: NEM\n",
            "Processed stock: NOW\n",
            "Processed stock: NTAP\n",
            "Processed stock: NUE\n",
            "Processed stock: NVDA\n",
            "Processed stock: MTD\n",
            "Processed stock: NDAQ\n",
            "Processed stock: MSI\n",
            "Processed stock: MSTR\n",
            "Processed stock: MU\n",
            "Processed stock: MRVL\n",
            "Processed stock: META\n",
            "Processed stock: MS\n",
            "Processed stock: MSFT\n",
            "Processed stock: MOS\n",
            "Processed stock: MLM\n",
            "Processed stock: MMM\n",
            "Processed stock: MMC\n",
            "Processed stock: MA\n",
            "Processed stock: MCO\n",
            "Processed stock: MCD\n",
            "Processed stock: NXPI\n",
            "Processed stock: MET\n",
            "Processed stock: MCK\n",
            "Processed stock: MRK\n",
            "Processed stock: MELI\n",
            "Processed stock: RJF\n",
            "Processed stock: RCL\n",
            "Processed stock: PWR\n",
            "Processed stock: PPG\n",
            "Processed stock: PTC\n",
            "Processed stock: PRU\n",
            "Processed stock: PHM\n",
            "Processed stock: PNR\n",
            "Processed stock: PNC\n",
            "Processed stock: ORCL\n",
            "Processed stock: ODFL\n",
            "Processed stock: OKE\n",
            "Processed stock: OVV\n",
            "Processed stock: POOL\n",
            "Processed stock: PFE\n",
            "Processed stock: PEG\n",
            "Processed stock: RTX\n",
            "Processed stock: OC\n",
            "Processed stock: PGR\n",
            "Processed stock: V\n",
            "Processed stock: VRTX\n",
            "Processed stock: USB\n",
            "Processed stock: VEEV\n",
            "Processed stock: TWLO\n",
            "Processed stock: TXN\n",
            "Processed stock: TT\n",
            "Processed stock: TSLA\n",
            "Processed stock: URI\n",
            "Processed stock: UNP\n",
            "Processed stock: T\n",
            "Processed stock: UNH\n",
            "Processed stock: TFC\n",
            "Processed stock: TEAM\n",
            "Processed stock: TRGP\n",
            "Processed stock: TRV\n",
            "Processed stock: TRMB\n",
            "Processed stock: SYF\n",
            "Processed stock: TSCO\n",
            "Processed stock: STE\n",
            "Processed stock: SYK\n",
            "Processed stock: SBUX\n",
            "Processed stock: VZ\n",
            "Processed stock: SCHW\n",
            "Processed stock: SLB\n",
            "Processed stock: SNPS\n",
            "Processed stock: WDC\n",
            "Processed stock: WELL\n",
            "Processed stock: WFC\n",
            "Processed stock: WST\n",
            "Processed stock: WTW\n",
            "Processed stock: WBD\n",
            "Processed stock: ZBH\n",
            "Processed stock: WY\n",
            "Processed stock: WAT\n",
            "No 'NM' values found in stock: ANET\n",
            "No 'NM' values found in stock: AXON\n",
            "No 'NM' values found in stock: ANSS\n",
            "No 'NM' values found in stock: AVGO\n",
            "No 'NM' values found in stock: AMZN\n",
            "No 'NM' values found in stock: AON\n",
            "No 'NM' values found in stock: APD\n",
            "No 'NM' values found in stock: AMGN\n",
            "No 'NM' values found in stock: AMD\n",
            "No 'NM' values found in stock: AMP\n",
            "No 'NM' values found in stock: AKAM\n",
            "No 'NM' values found in stock: AMAT\n",
            "No 'NM' values found in stock: ALNY\n",
            "No 'NM' values found in stock: ADP\n",
            "No 'NM' values found in stock: AJG\n",
            "No 'NM' values found in stock: AIZ\n",
            "No 'NM' values found in stock: ADSK\n",
            "No 'NM' values found in stock: A\n",
            "No 'NM' values found in stock: ADBE\n",
            "No 'NM' values found in stock: ADI\n",
            "No 'NM' values found in stock: AXP\n",
            "No 'NM' values found in stock: AAPL\n",
            "No 'NM' values found in stock: ACGL\n",
            "No 'NM' values found in stock: ABBV\n",
            "No 'NM' values found in stock: BKNG\n",
            "No 'NM' values found in stock: BK\n",
            "No 'NM' values found in stock: BR\n",
            "No 'NM' values found in stock: BAC\n",
            "No 'NM' values found in stock: BKR\n",
            "No 'NM' values found in stock: BLK\n",
            "No 'NM' values found in stock: BXP\n",
            "No 'NM' values found in stock: BBY\n",
            "No 'NM' values found in stock: CRM\n",
            "No 'NM' values found in stock: CRH\n",
            "No 'NM' values found in stock: CSCO\n",
            "No 'NM' values found in stock: CPRT\n",
            "No 'NM' values found in stock: COR\n",
            "No 'NM' values found in stock: COP\n",
            "No 'NM' values found in stock: COST\n",
            "No 'NM' values found in stock: CPB\n",
            "No 'NM' values found in stock: CNH\n",
            "No 'NM' values found in stock: COO\n",
            "No 'NM' values found in stock: CMS\n",
            "No 'NM' values found in stock: COF\n",
            "No 'NM' values found in stock: CMI\n",
            "No 'NM' values found in stock: CI\n",
            "No 'NM' values found in stock: CMCSA\n",
            "No 'NM' values found in stock: CLX\n",
            "No 'NM' values found in stock: CMG\n",
            "No 'NM' values found in stock: CHRW\n",
            "No 'NM' values found in stock: CBRE\n",
            "No 'NM' values found in stock: CAT\n",
            "No 'NM' values found in stock: CAH\n",
            "No 'NM' values found in stock: CDNS\n",
            "No 'NM' values found in stock: CVX\n",
            "No 'NM' values found in stock: C\n",
            "No 'NM' values found in stock: FICO\n",
            "No 'NM' values found in stock: FIS\n",
            "No 'NM' values found in stock: FERG\n",
            "No 'NM' values found in stock: EXC\n",
            "No 'NM' values found in stock: FI\n",
            "No 'NM' values found in stock: FDX\n",
            "No 'NM' values found in stock: FBIN\n",
            "No 'NM' values found in stock: EQT\n",
            "No 'NM' values found in stock: FDS\n",
            "No 'NM' values found in stock: EXPD\n",
            "No 'NM' values found in stock: FANG\n",
            "No 'NM' values found in stock: ETN\n",
            "No 'NM' values found in stock: ES\n",
            "No 'NM' values found in stock: EIX\n",
            "No 'NM' values found in stock: EQIX\n",
            "No 'NM' values found in stock: EME\n",
            "No 'NM' values found in stock: ELV\n",
            "No 'NM' values found in stock: DXCM\n",
            "No 'NM' values found in stock: EA\n",
            "No 'NM' values found in stock: DHR\n",
            "No 'NM' values found in stock: DGX\n",
            "No 'NM' values found in stock: DIS\n",
            "No 'NM' values found in stock: DLR\n",
            "No 'NM' values found in stock: ECL\n",
            "No 'NM' values found in stock: FTV\n",
            "No 'NM' values found in stock: DAL\n",
            "No 'NM' values found in stock: DE\n",
            "No 'NM' values found in stock: DFS\n",
            "No 'NM' values found in stock: IEX\n",
            "No 'NM' values found in stock: INTC\n",
            "No 'NM' values found in stock: ISRG\n",
            "No 'NM' values found in stock: IRM\n",
            "No 'NM' values found in stock: HUM\n",
            "No 'NM' values found in stock: IQV\n",
            "No 'NM' values found in stock: IP\n",
            "No 'NM' values found in stock: INTU\n",
            "No 'NM' values found in stock: IDXX\n",
            "No 'NM' values found in stock: HUBB\n",
            "No 'NM' values found in stock: HPE\n",
            "No 'NM' values found in stock: IBM\n",
            "No 'NM' values found in stock: HON\n",
            "No 'NM' values found in stock: HOLX\n",
            "No 'NM' values found in stock: HES\n",
            "No 'NM' values found in stock: HBAN\n",
            "No 'NM' values found in stock: HIG\n",
            "No 'NM' values found in stock: HD\n",
            "No 'NM' values found in stock: HCA\n",
            "No 'NM' values found in stock: GS\n",
            "No 'NM' values found in stock: GWW\n",
            "No 'NM' values found in stock: GOOGL\n",
            "No 'NM' values found in stock: GE\n",
            "No 'NM' values found in stock: GDDY\n",
            "No 'NM' values found in stock: IT\n",
            "No 'NM' values found in stock: KR\n",
            "No 'NM' values found in stock: LDOS\n",
            "No 'NM' values found in stock: LRCX\n",
            "No 'NM' values found in stock: LLY\n",
            "No 'NM' values found in stock: LII\n",
            "No 'NM' values found in stock: LH\n",
            "No 'NM' values found in stock: JNPR\n",
            "No 'NM' values found in stock: LNG\n",
            "No 'NM' values found in stock: LOW\n",
            "No 'NM' values found in stock: KHC\n",
            "No 'NM' values found in stock: JPM\n",
            "No 'NM' values found in stock: KEYS\n",
            "No 'NM' values found in stock: LULU\n",
            "No 'NM' values found in stock: KMI\n",
            "No 'NM' values found in stock: KMB\n",
            "No 'NM' values found in stock: KKR\n",
            "No 'NM' values found in stock: KMX\n",
            "No 'NM' values found in stock: JBHT\n",
            "No 'NM' values found in stock: J\n",
            "No 'NM' values found in stock: NFLX\n",
            "No 'NM' values found in stock: NOC\n",
            "No 'NM' values found in stock: NEM\n",
            "No 'NM' values found in stock: NOW\n",
            "No 'NM' values found in stock: NTAP\n",
            "No 'NM' values found in stock: NUE\n",
            "No 'NM' values found in stock: NVDA\n",
            "No 'NM' values found in stock: MTD\n",
            "No 'NM' values found in stock: NDAQ\n",
            "No 'NM' values found in stock: MSI\n",
            "No 'NM' values found in stock: MSTR\n",
            "No 'NM' values found in stock: MU\n",
            "No 'NM' values found in stock: MRVL\n",
            "No 'NM' values found in stock: META\n",
            "No 'NM' values found in stock: MS\n",
            "No 'NM' values found in stock: MSFT\n",
            "No 'NM' values found in stock: MOS\n",
            "No 'NM' values found in stock: MLM\n",
            "No 'NM' values found in stock: MMM\n",
            "No 'NM' values found in stock: MMC\n",
            "No 'NM' values found in stock: MA\n",
            "No 'NM' values found in stock: MCO\n",
            "No 'NM' values found in stock: MCD\n",
            "No 'NM' values found in stock: NXPI\n",
            "No 'NM' values found in stock: MET\n",
            "No 'NM' values found in stock: MCK\n",
            "No 'NM' values found in stock: MRK\n",
            "No 'NM' values found in stock: MELI\n",
            "No 'NM' values found in stock: RJF\n",
            "No 'NM' values found in stock: RCL\n",
            "No 'NM' values found in stock: PWR\n",
            "No 'NM' values found in stock: PPG\n",
            "No 'NM' values found in stock: PTC\n",
            "No 'NM' values found in stock: PRU\n",
            "No 'NM' values found in stock: PHM\n",
            "No 'NM' values found in stock: PNR\n",
            "No 'NM' values found in stock: PNC\n",
            "No 'NM' values found in stock: ORCL\n",
            "No 'NM' values found in stock: ODFL\n",
            "No 'NM' values found in stock: OKE\n",
            "No 'NM' values found in stock: OVV\n",
            "No 'NM' values found in stock: POOL\n",
            "No 'NM' values found in stock: PFE\n",
            "No 'NM' values found in stock: PEG\n",
            "No 'NM' values found in stock: RTX\n",
            "No 'NM' values found in stock: OC\n",
            "No 'NM' values found in stock: PGR\n",
            "No 'NM' values found in stock: V\n",
            "No 'NM' values found in stock: VRTX\n",
            "No 'NM' values found in stock: USB\n",
            "No 'NM' values found in stock: VEEV\n",
            "No 'NM' values found in stock: TWLO\n",
            "No 'NM' values found in stock: TXN\n",
            "No 'NM' values found in stock: TT\n",
            "No 'NM' values found in stock: TSLA\n",
            "No 'NM' values found in stock: URI\n",
            "No 'NM' values found in stock: UNP\n",
            "No 'NM' values found in stock: T\n",
            "No 'NM' values found in stock: UNH\n",
            "No 'NM' values found in stock: TFC\n",
            "No 'NM' values found in stock: TEAM\n",
            "No 'NM' values found in stock: TRGP\n",
            "No 'NM' values found in stock: TRV\n",
            "No 'NM' values found in stock: TRMB\n",
            "No 'NM' values found in stock: SYF\n",
            "No 'NM' values found in stock: TSCO\n",
            "No 'NM' values found in stock: STE\n",
            "No 'NM' values found in stock: SYK\n",
            "No 'NM' values found in stock: SBUX\n",
            "No 'NM' values found in stock: VZ\n",
            "No 'NM' values found in stock: SCHW\n",
            "No 'NM' values found in stock: SLB\n",
            "No 'NM' values found in stock: SNPS\n",
            "No 'NM' values found in stock: WDC\n",
            "No 'NM' values found in stock: WELL\n",
            "No 'NM' values found in stock: WFC\n",
            "No 'NM' values found in stock: WST\n",
            "No 'NM' values found in stock: WTW\n",
            "No 'NM' values found in stock: WBD\n",
            "No 'NM' values found in stock: ZBH\n",
            "No 'NM' values found in stock: WY\n",
            "No 'NM' values found in stock: WAT\n"
          ]
        }
      ],
      "source": [
        "# %%\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 1. Define the replacement function\n",
        "def replace_NM_with_prev_or_zero(df):\n",
        "    \"\"\"\n",
        "    Replace all occurrences of 'NM' in any column with the value from the row above in that column.\n",
        "    If the row above is inaccessible, replace 'NM' with 0.0.\n",
        "\n",
        "    Parameters:\n",
        "    - df (pd.DataFrame): The input DataFrame to process.\n",
        "\n",
        "    Returns:\n",
        "    - pd.DataFrame: The processed DataFrame with 'NM' replaced appropriately.\n",
        "    \"\"\"\n",
        "    df = df.copy()  # To avoid modifying the original DataFrame\n",
        "\n",
        "    # Replace 'NM' with NaN to facilitate forward filling\n",
        "    df.replace('NM', np.nan, inplace=True)\n",
        "\n",
        "    # Forward fill to replace NaN with the value from the row above\n",
        "    df.fillna(method='ffill', inplace=True)\n",
        "\n",
        "    # For any remaining NaN (which were 'NM' in the first row), replace with 0.0\n",
        "    df.fillna(0.0, inplace=True)\n",
        "\n",
        "    # Convert all columns to numeric types where possible\n",
        "    for col in df.columns:\n",
        "        df[col] = pd.to_numeric(df[col], errors='ignore')\n",
        "\n",
        "    return df\n",
        "\n",
        "# 2. Apply the function to all stocks in stock_data\n",
        "for ticker, df in stock_data.items():\n",
        "    stock_data[ticker] = replace_NM_with_prev_or_zero(df)\n",
        "    print(f\"Processed stock: {ticker}\")\n",
        "\n",
        "# 3. Verify the replacement\n",
        "def verify_replacement(stock_data):\n",
        "    \"\"\"\n",
        "    Verify that 'NM' has been replaced with previous row's value or 0.0 in all columns for all stocks.\n",
        "\n",
        "    Parameters:\n",
        "    - stock_data (dict): Dictionary containing stock tickers as keys and DataFrames as values.\n",
        "\n",
        "    Returns:\n",
        "    - None\n",
        "    \"\"\"\n",
        "    for ticker, df in stock_data.items():\n",
        "        # Check if 'NM' still exists in any column\n",
        "        if (df.astype(str) == 'NM').any().any():\n",
        "            print(f\"'NM' still found in stock: {ticker}\")\n",
        "        else:\n",
        "            print(f\"No 'NM' values found in stock: {ticker}\")\n",
        "\n",
        "# Run the verification\n",
        "verify_replacement(stock_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSSHDQSseE_w",
        "outputId": "ef86d23a-43e1-4ea9-e676-ca61c35b763b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping CatBoost for ANET as it has already been processed.\n",
            "Skipping CatBoost for AXON as it has already been processed.\n",
            "Skipping CatBoost for ANSS as it has already been processed.\n",
            "Skipping CatBoost for AVGO as it has already been processed.\n",
            "Skipping CatBoost for AMZN as it has already been processed.\n",
            "Skipping CatBoost for AON as it has already been processed.\n",
            "Skipping CatBoost for APD as it has already been processed.\n",
            "Skipping CatBoost for AMGN as it has already been processed.\n",
            "Skipping CatBoost for AMD as it has already been processed.\n",
            "Skipping CatBoost for AMP as it has already been processed.\n",
            "Skipping CatBoost for AKAM as it has already been processed.\n",
            "Skipping CatBoost for AMAT as it has already been processed.\n",
            "Skipping CatBoost for ALNY as it has already been processed.\n",
            "Skipping CatBoost for ADP as it has already been processed.\n",
            "Skipping CatBoost for AJG as it has already been processed.\n",
            "Skipping CatBoost for AIZ as it has already been processed.\n",
            "Skipping CatBoost for ADSK as it has already been processed.\n",
            "Skipping CatBoost for A as it has already been processed.\n",
            "Skipping CatBoost for ADBE as it has already been processed.\n",
            "Skipping CatBoost for ADI as it has already been processed.\n",
            "Skipping CatBoost for AXP as it has already been processed.\n",
            "Skipping CatBoost for AAPL as it has already been processed.\n",
            "Skipping CatBoost for ACGL as it has already been processed.\n",
            "Skipping CatBoost for ABBV as it has already been processed.\n",
            "Skipping CatBoost for BKNG as it has already been processed.\n",
            "Skipping CatBoost for BK as it has already been processed.\n",
            "Skipping CatBoost for BR as it has already been processed.\n",
            "Skipping CatBoost for BAC as it has already been processed.\n",
            "Skipping CatBoost for BKR as it has already been processed.\n",
            "Skipping CatBoost for BLK as it has already been processed.\n",
            "Skipping CatBoost for BXP as it has already been processed.\n",
            "Skipping CatBoost for BBY as it has already been processed.\n",
            "Skipping CatBoost for CRM as it has already been processed.\n",
            "Skipping CatBoost for CRH as it has already been processed.\n",
            "Skipping CatBoost for CSCO as it has already been processed.\n",
            "Skipping CatBoost for CPRT as it has already been processed.\n",
            "Skipping CatBoost for COR as it has already been processed.\n",
            "Skipping CatBoost for COP as it has already been processed.\n",
            "Skipping CatBoost for COST as it has already been processed.\n",
            "Skipping CatBoost for CPB as it has already been processed.\n",
            "Skipping CatBoost for CNH as it has already been processed.\n",
            "Skipping CatBoost for COO as it has already been processed.\n",
            "Skipping CatBoost for CMS as it has already been processed.\n",
            "Skipping CatBoost for COF as it has already been processed.\n",
            "Skipping CatBoost for CMI as it has already been processed.\n",
            "Skipping CatBoost for CI as it has already been processed.\n",
            "Skipping CatBoost for CMCSA as it has already been processed.\n",
            "Skipping CatBoost for CLX as it has already been processed.\n",
            "Skipping CatBoost for CMG as it has already been processed.\n",
            "Skipping CatBoost for CHRW as it has already been processed.\n",
            "Skipping CatBoost for CBRE as it has already been processed.\n",
            "Skipping CatBoost for CAT as it has already been processed.\n",
            "Skipping CatBoost for CAH as it has already been processed.\n",
            "Skipping CatBoost for CDNS as it has already been processed.\n",
            "Skipping CatBoost for CVX as it has already been processed.\n",
            "Skipping CatBoost for C as it has already been processed.\n",
            "Skipping CatBoost for FICO as it has already been processed.\n",
            "Skipping CatBoost for FIS as it has already been processed.\n",
            "Skipping CatBoost for FERG as it has already been processed.\n",
            "Skipping CatBoost for EXC as it has already been processed.\n",
            "Skipping CatBoost for FI as it has already been processed.\n",
            "Skipping CatBoost for FDX as it has already been processed.\n",
            "Skipping CatBoost for FBIN as it has already been processed.\n",
            "Skipping CatBoost for EQT as it has already been processed.\n",
            "Skipping CatBoost for FDS as it has already been processed.\n",
            "Skipping CatBoost for EXPD as it has already been processed.\n",
            "Skipping CatBoost for FANG as it has already been processed.\n",
            "Skipping CatBoost for ETN as it has already been processed.\n",
            "Skipping CatBoost for ES as it has already been processed.\n",
            "Skipping CatBoost for EIX as it has already been processed.\n",
            "Skipping CatBoost for EQIX as it has already been processed.\n",
            "Skipping CatBoost for EME as it has already been processed.\n",
            "Skipping CatBoost for ELV as it has already been processed.\n",
            "Skipping CatBoost for DXCM as it has already been processed.\n",
            "Skipping CatBoost for EA as it has already been processed.\n",
            "Skipping CatBoost for DHR as it has already been processed.\n",
            "Skipping CatBoost for DGX as it has already been processed.\n",
            "Skipping CatBoost for DIS as it has already been processed.\n",
            "Skipping CatBoost for DLR as it has already been processed.\n",
            "Skipping CatBoost for ECL as it has already been processed.\n",
            "\n",
            "Processing CatBoost model for stock: FTV\n",
            "Loaded existing CatBoost study for FTV.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[W 2024-12-14 13:34:13,479] Trial 6 failed with parameters: {'iterations': 1469, 'depth': 6, 'learning_rate': 0.049425710225013554, 'l2_leaf_reg': 9.031268910504988, 'random_strength': 8.94137918504006, 'bagging_temperature': 7.755651137844591} because of the following error: CatBoostError('catboost/private/libs/algo/tensor_search_helpers.cpp:563: Too few sampling units (subsample=0.8, bootstrap_type=MVS): please increase sampling rate or disable sampling').\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"<ipython-input-12-d94ef7ac48f6>\", line 89, in objective_cb\n",
            "    model.fit(train_pool, eval_set=(X_val_fold, y_val_fold), early_stopping_rounds=100, use_best_model=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/catboost/core.py\", line 5873, in fit\n",
            "    return self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/catboost/core.py\", line 2410, in _fit\n",
            "    self._train(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/catboost/core.py\", line 1790, in _train\n",
            "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
            "  File \"_catboost.pyx\", line 5017, in _catboost._CatBoost._train\n",
            "  File \"_catboost.pyx\", line 5066, in _catboost._CatBoost._train\n",
            "_catboost.CatBoostError: catboost/private/libs/algo/tensor_search_helpers.cpp:563: Too few sampling units (subsample=0.8, bootstrap_type=MVS): please increase sampling rate or disable sampling\n",
            "[W 2024-12-14 13:34:13,488] Trial 6 failed with value None.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "An error occurred while processing CatBoost for FTV: catboost/private/libs/algo/tensor_search_helpers.cpp:563: Too few sampling units (subsample=0.8, bootstrap_type=MVS): please increase sampling rate or disable sampling\n",
            "Saved CatBoost parameters, forecasts, and performance data for FTV.\n",
            "Skipping CatBoost for DAL as it has already been processed.\n",
            "Skipping CatBoost for DE as it has already been processed.\n",
            "Skipping CatBoost for DFS as it has already been processed.\n",
            "Skipping CatBoost for IEX as it has already been processed.\n",
            "Skipping CatBoost for INTC as it has already been processed.\n",
            "Skipping CatBoost for ISRG as it has already been processed.\n",
            "Skipping CatBoost for IRM as it has already been processed.\n",
            "Skipping CatBoost for HUM as it has already been processed.\n",
            "Skipping CatBoost for IQV as it has already been processed.\n",
            "Skipping CatBoost for IP as it has already been processed.\n",
            "Skipping CatBoost for INTU as it has already been processed.\n",
            "Skipping CatBoost for IDXX as it has already been processed.\n",
            "Skipping CatBoost for HUBB as it has already been processed.\n",
            "\n",
            "Processing CatBoost model for stock: HPE\n",
            "Loaded existing CatBoost study for HPE.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[W 2024-12-14 13:34:14,773] Trial 4 failed with parameters: {'iterations': 1253, 'depth': 8, 'learning_rate': 0.06417049696488936, 'l2_leaf_reg': 6.584087808694645, 'random_strength': 5.848436248403029, 'bagging_temperature': 3.812430013729945} because of the following error: CatBoostError('catboost/private/libs/algo/tensor_search_helpers.cpp:563: Too few sampling units (subsample=0.8, bootstrap_type=MVS): please increase sampling rate or disable sampling').\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"<ipython-input-12-d94ef7ac48f6>\", line 89, in objective_cb\n",
            "    model.fit(train_pool, eval_set=(X_val_fold, y_val_fold), early_stopping_rounds=100, use_best_model=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/catboost/core.py\", line 5873, in fit\n",
            "    return self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/catboost/core.py\", line 2410, in _fit\n",
            "    self._train(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/catboost/core.py\", line 1790, in _train\n",
            "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
            "  File \"_catboost.pyx\", line 5017, in _catboost._CatBoost._train\n",
            "  File \"_catboost.pyx\", line 5066, in _catboost._CatBoost._train\n",
            "_catboost.CatBoostError: catboost/private/libs/algo/tensor_search_helpers.cpp:563: Too few sampling units (subsample=0.8, bootstrap_type=MVS): please increase sampling rate or disable sampling\n",
            "[W 2024-12-14 13:34:14,776] Trial 4 failed with value None.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "An error occurred while processing CatBoost for HPE: catboost/private/libs/algo/tensor_search_helpers.cpp:563: Too few sampling units (subsample=0.8, bootstrap_type=MVS): please increase sampling rate or disable sampling\n",
            "Saved CatBoost parameters, forecasts, and performance data for HPE.\n",
            "Skipping CatBoost for IBM as it has already been processed.\n",
            "Skipping CatBoost for HON as it has already been processed.\n",
            "Skipping CatBoost for HOLX as it has already been processed.\n",
            "Skipping CatBoost for HES as it has already been processed.\n",
            "Skipping CatBoost for HBAN as it has already been processed.\n",
            "Skipping CatBoost for HIG as it has already been processed.\n",
            "Skipping CatBoost for HD as it has already been processed.\n",
            "Skipping CatBoost for HCA as it has already been processed.\n",
            "Skipping CatBoost for GS as it has already been processed.\n",
            "Skipping CatBoost for GWW as it has already been processed.\n",
            "Skipping CatBoost for GOOGL as it has already been processed.\n",
            "Skipping CatBoost for GE as it has already been processed.\n",
            "\n",
            "Processing CatBoost model for stock: GDDY\n",
            "Loaded existing CatBoost study for GDDY.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[W 2024-12-14 13:34:20,227] Trial 3 failed with parameters: {'iterations': 1341, 'depth': 7, 'learning_rate': 0.0012631633790510402, 'l2_leaf_reg': 10.967525212791102, 'random_strength': 7.088067719332659, 'bagging_temperature': 4.520108300490984} because of the following error: CatBoostError('catboost/private/libs/algo/tensor_search_helpers.cpp:563: Too few sampling units (subsample=0.8, bootstrap_type=MVS): please increase sampling rate or disable sampling').\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"<ipython-input-12-d94ef7ac48f6>\", line 89, in objective_cb\n",
            "    model.fit(train_pool, eval_set=(X_val_fold, y_val_fold), early_stopping_rounds=100, use_best_model=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/catboost/core.py\", line 5873, in fit\n",
            "    return self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/catboost/core.py\", line 2410, in _fit\n",
            "    self._train(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/catboost/core.py\", line 1790, in _train\n",
            "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
            "  File \"_catboost.pyx\", line 5017, in _catboost._CatBoost._train\n",
            "  File \"_catboost.pyx\", line 5066, in _catboost._CatBoost._train\n",
            "_catboost.CatBoostError: catboost/private/libs/algo/tensor_search_helpers.cpp:563: Too few sampling units (subsample=0.8, bootstrap_type=MVS): please increase sampling rate or disable sampling\n",
            "[W 2024-12-14 13:34:20,229] Trial 3 failed with value None.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "An error occurred while processing CatBoost for GDDY: catboost/private/libs/algo/tensor_search_helpers.cpp:563: Too few sampling units (subsample=0.8, bootstrap_type=MVS): please increase sampling rate or disable sampling\n",
            "Saved CatBoost parameters, forecasts, and performance data for GDDY.\n",
            "Skipping CatBoost for IT as it has already been processed.\n",
            "Skipping CatBoost for KR as it has already been processed.\n",
            "Skipping CatBoost for LDOS as it has already been processed.\n",
            "Skipping CatBoost for LRCX as it has already been processed.\n",
            "Skipping CatBoost for LLY as it has already been processed.\n",
            "Skipping CatBoost for LII as it has already been processed.\n",
            "Skipping CatBoost for LH as it has already been processed.\n",
            "Skipping CatBoost for JNPR as it has already been processed.\n",
            "Skipping CatBoost for LNG as it has already been processed.\n",
            "Skipping CatBoost for LOW as it has already been processed.\n",
            "\n",
            "Processing CatBoost model for stock: KHC\n",
            "Loaded existing CatBoost study for KHC.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[W 2024-12-14 13:34:20,940] Trial 2 failed with parameters: {'iterations': 1407, 'depth': 9, 'learning_rate': 0.00018586624458150262, 'l2_leaf_reg': 13.696385111227436, 'random_strength': 1.8889620758231518, 'bagging_temperature': 9.365590847483356} because of the following error: CatBoostError('catboost/private/libs/algo/tensor_search_helpers.cpp:563: Too few sampling units (subsample=0.8, bootstrap_type=MVS): please increase sampling rate or disable sampling').\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"<ipython-input-12-d94ef7ac48f6>\", line 89, in objective_cb\n",
            "    model.fit(train_pool, eval_set=(X_val_fold, y_val_fold), early_stopping_rounds=100, use_best_model=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/catboost/core.py\", line 5873, in fit\n",
            "    return self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/catboost/core.py\", line 2410, in _fit\n",
            "    self._train(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/catboost/core.py\", line 1790, in _train\n",
            "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
            "  File \"_catboost.pyx\", line 5017, in _catboost._CatBoost._train\n",
            "  File \"_catboost.pyx\", line 5066, in _catboost._CatBoost._train\n",
            "_catboost.CatBoostError: catboost/private/libs/algo/tensor_search_helpers.cpp:563: Too few sampling units (subsample=0.8, bootstrap_type=MVS): please increase sampling rate or disable sampling\n",
            "[W 2024-12-14 13:34:20,942] Trial 2 failed with value None.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "An error occurred while processing CatBoost for KHC: catboost/private/libs/algo/tensor_search_helpers.cpp:563: Too few sampling units (subsample=0.8, bootstrap_type=MVS): please increase sampling rate or disable sampling\n",
            "Saved CatBoost parameters, forecasts, and performance data for KHC.\n",
            "Skipping CatBoost for JPM as it has already been processed.\n",
            "Skipping CatBoost for KEYS as it has already been processed.\n",
            "Skipping CatBoost for LULU as it has already been processed.\n",
            "\n",
            "Processing CatBoost model for stock: KMI\n",
            "Loaded existing CatBoost study for KMI.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-12-14 13:34:34,884] Trial 17 finished with value: 52.463033642646344 and parameters: {'iterations': 1362, 'depth': 9, 'learning_rate': 0.102649904701892, 'l2_leaf_reg': 14.763253587075189, 'random_strength': 3.466476022901284, 'bagging_temperature': 2.567273778021719}. Best is trial 14 with value: 51.65390718457595.\n",
            "[I 2024-12-14 13:34:35,727] Trial 18 pruned. \n",
            "[I 2024-12-14 13:34:37,761] Trial 19 pruned. \n",
            "[I 2024-12-14 13:34:53,524] Trial 20 finished with value: 53.38608628192907 and parameters: {'iterations': 1583, 'depth': 9, 'learning_rate': 0.11248204626861649, 'l2_leaf_reg': 8.94355403362629, 'random_strength': 9.779242247936455, 'bagging_temperature': 1.8574186534436978}. Best is trial 14 with value: 51.65390718457595.\n",
            "[I 2024-12-14 13:35:13,225] Trial 21 pruned. \n",
            "[I 2024-12-14 13:35:28,294] Trial 22 finished with value: 51.73110748303703 and parameters: {'iterations': 1309, 'depth': 9, 'learning_rate': 0.07892115613677099, 'l2_leaf_reg': 14.809598986566225, 'random_strength': 2.997822639085239, 'bagging_temperature': 2.877732308465517}. Best is trial 14 with value: 51.65390718457595.\n",
            "[I 2024-12-14 13:35:41,557] Trial 23 finished with value: 51.227629603606836 and parameters: {'iterations': 813, 'depth': 9, 'learning_rate': 0.1009617603612474, 'l2_leaf_reg': 13.621725132115298, 'random_strength': 3.2322990461465304, 'bagging_temperature': 3.2163437392010645}. Best is trial 23 with value: 51.227629603606836.\n",
            "[I 2024-12-14 13:35:43,606] Trial 24 pruned. \n",
            "[I 2024-12-14 13:35:53,792] Trial 25 pruned. \n",
            "[I 2024-12-14 13:36:14,058] Trial 26 pruned. \n",
            "[I 2024-12-14 13:36:27,009] Trial 27 finished with value: 52.590263215163674 and parameters: {'iterations': 1087, 'depth': 9, 'learning_rate': 0.140608658536728, 'l2_leaf_reg': 10.238851889150645, 'random_strength': 4.898399356854332, 'bagging_temperature': 1.0409593291820705}. Best is trial 23 with value: 51.227629603606836.\n",
            "[I 2024-12-14 13:36:45,597] Trial 28 pruned. \n",
            "[I 2024-12-14 13:36:47,971] Trial 29 pruned. \n",
            "[I 2024-12-14 13:36:49,627] Trial 30 pruned. \n",
            "[I 2024-12-14 13:36:56,889] Trial 31 pruned. \n",
            "[I 2024-12-14 13:37:10,882] Trial 32 finished with value: 52.52340466422245 and parameters: {'iterations': 1253, 'depth': 9, 'learning_rate': 0.08723061786298558, 'l2_leaf_reg': 14.981017813501683, 'random_strength': 3.2406335574741263, 'bagging_temperature': 2.471049406602341}. Best is trial 23 with value: 51.227629603606836.\n",
            "[I 2024-12-14 13:37:15,601] Trial 33 pruned. \n",
            "[I 2024-12-14 13:37:18,904] Trial 34 pruned. \n",
            "[I 2024-12-14 13:37:24,804] Trial 35 pruned. \n",
            "[I 2024-12-14 13:37:33,908] Trial 36 pruned. \n",
            "[I 2024-12-14 13:37:47,098] Trial 37 finished with value: 53.115423806992034 and parameters: {'iterations': 1089, 'depth': 9, 'learning_rate': 0.10904816394311312, 'l2_leaf_reg': 6.750383817867926, 'random_strength': 5.220637819901993, 'bagging_temperature': 3.078707334420643}. Best is trial 23 with value: 51.227629603606836.\n",
            "[I 2024-12-14 13:37:53,871] Trial 38 pruned. \n",
            "[I 2024-12-14 13:37:55,266] Trial 39 pruned. \n",
            "[I 2024-12-14 13:38:00,796] Trial 40 pruned. \n",
            "[I 2024-12-14 13:38:15,545] Trial 41 pruned. \n",
            "[I 2024-12-14 13:38:20,297] Trial 42 pruned. \n",
            "[I 2024-12-14 13:38:28,796] Trial 43 pruned. \n",
            "[I 2024-12-14 13:38:34,492] Trial 44 pruned. \n",
            "[I 2024-12-14 13:38:36,099] Trial 45 pruned. \n",
            "[I 2024-12-14 13:38:38,370] Trial 46 pruned. \n",
            "[I 2024-12-14 13:38:44,665] Trial 47 pruned. \n",
            "[I 2024-12-14 13:38:50,308] Trial 48 pruned. \n",
            "[I 2024-12-14 13:38:52,764] Trial 49 pruned. \n",
            "[I 2024-12-14 13:38:59,126] Trial 50 pruned. \n",
            "[I 2024-12-14 13:39:20,408] Trial 51 pruned. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params for KMI (CatBoost): {'iterations': 813, 'depth': 9, 'learning_rate': 0.1009617603612474, 'l2_leaf_reg': 13.621725132115298, 'random_strength': 3.2322990461465304, 'bagging_temperature': 3.2163437392010645}\n",
            "Best RMSE for KMI: 51.227629603606836\n",
            "Best R² for KMI: 0.07553404743757908\n",
            "Best MAPE for KMI: 24051381499219.273\n",
            "Completed CatBoost for KMI. Forecast Return: 2.1501%\n",
            "Saved CatBoost parameters, forecasts, and performance data for KMI.\n",
            "\n",
            "Processing CatBoost model for stock: KMB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-12-14 13:39:52,124] A new study created in RDB with name: cb_study_KMB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new CatBoost study for KMB.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-12-14 13:39:58,004] Trial 0 finished with value: 24.541932602657923 and parameters: {'iterations': 2814, 'depth': 6, 'learning_rate': 0.006723227311330493, 'l2_leaf_reg': 11.57157848654055, 'random_strength': 6.975787742376759, 'bagging_temperature': 0.12095213511613245}. Best is trial 0 with value: 24.541932602657923.\n",
            "[I 2024-12-14 13:40:03,969] Trial 1 finished with value: 25.36234330787552 and parameters: {'iterations': 2277, 'depth': 7, 'learning_rate': 0.20569364012746885, 'l2_leaf_reg': 7.016045711230461, 'random_strength': 5.064927895719676, 'bagging_temperature': 4.889590685753486}. Best is trial 0 with value: 24.541932602657923.\n",
            "[I 2024-12-14 13:41:24,661] Trial 2 finished with value: 24.83611281923261 and parameters: {'iterations': 821, 'depth': 11, 'learning_rate': 0.009582982542828617, 'l2_leaf_reg': 2.4431199403901185, 'random_strength': 8.166498191779954, 'bagging_temperature': 0.3529583374721956}. Best is trial 0 with value: 24.541932602657923.\n",
            "[I 2024-12-14 13:41:26,096] Trial 3 finished with value: 23.99222426021838 and parameters: {'iterations': 1885, 'depth': 4, 'learning_rate': 0.26298936571642795, 'l2_leaf_reg': 9.66174493373097, 'random_strength': 8.311084465525061, 'bagging_temperature': 8.331085499117034}. Best is trial 3 with value: 23.99222426021838.\n",
            "[I 2024-12-14 13:41:28,751] Trial 4 finished with value: 24.675651044833497 and parameters: {'iterations': 1464, 'depth': 6, 'learning_rate': 0.04200649760533743, 'l2_leaf_reg': 14.482327038233626, 'random_strength': 2.28197828733785, 'bagging_temperature': 4.60601614227134}. Best is trial 3 with value: 23.99222426021838.\n",
            "[I 2024-12-14 13:41:31,552] Trial 5 pruned. \n",
            "[I 2024-12-14 13:41:37,325] Trial 6 finished with value: 24.36366564663432 and parameters: {'iterations': 2046, 'depth': 7, 'learning_rate': 0.027737653093062933, 'l2_leaf_reg': 6.267517161502625, 'random_strength': 7.910028867754099, 'bagging_temperature': 5.252270816608586}. Best is trial 3 with value: 23.99222426021838.\n",
            "[I 2024-12-14 13:41:40,657] Trial 7 finished with value: 24.51083668568781 and parameters: {'iterations': 1135, 'depth': 5, 'learning_rate': 0.010072415691565802, 'l2_leaf_reg': 6.485771676202486, 'random_strength': 6.643029430788087, 'bagging_temperature': 7.957922002472369}. Best is trial 3 with value: 23.99222426021838.\n",
            "[I 2024-12-14 13:42:03,335] Trial 8 pruned. \n",
            "[I 2024-12-14 13:42:21,911] Trial 9 finished with value: 24.569988813559462 and parameters: {'iterations': 2067, 'depth': 6, 'learning_rate': 0.001722179348292355, 'l2_leaf_reg': 3.503741233425588, 'random_strength': 7.912679047135432, 'bagging_temperature': 4.400607840751195}. Best is trial 3 with value: 23.99222426021838.\n",
            "[I 2024-12-14 13:42:27,567] Trial 10 pruned. \n",
            "[I 2024-12-14 13:42:34,927] Trial 11 pruned. \n",
            "[I 2024-12-14 13:42:37,917] Trial 12 pruned. \n",
            "[I 2024-12-14 13:42:49,198] Trial 13 finished with value: 24.481836811964403 and parameters: {'iterations': 1636, 'depth': 4, 'learning_rate': 0.0012094057066143113, 'l2_leaf_reg': 12.169939623428265, 'random_strength': 8.812195553028246, 'bagging_temperature': 2.843528510782111}. Best is trial 3 with value: 23.99222426021838.\n",
            "[I 2024-12-14 13:42:50,929] Trial 14 pruned. \n",
            "[I 2024-12-14 13:42:52,836] Trial 15 finished with value: 24.12841346548532 and parameters: {'iterations': 1796, 'depth': 5, 'learning_rate': 0.09978362736663537, 'l2_leaf_reg': 5.216903930965879, 'random_strength': 8.615532136791334, 'bagging_temperature': 6.407902297583802}. Best is trial 3 with value: 23.99222426021838.\n",
            "[I 2024-12-14 13:42:54,268] Trial 16 finished with value: 24.19791324602338 and parameters: {'iterations': 1743, 'depth': 4, 'learning_rate': 0.11082223321232364, 'l2_leaf_reg': 4.611061704738448, 'random_strength': 9.01234845395315, 'bagging_temperature': 8.131994439246766}. Best is trial 3 with value: 23.99222426021838.\n",
            "[I 2024-12-14 13:42:55,401] Trial 17 pruned. \n",
            "[I 2024-12-14 13:42:57,259] Trial 18 finished with value: 24.453575548891326 and parameters: {'iterations': 580, 'depth': 5, 'learning_rate': 0.09493372574815145, 'l2_leaf_reg': 13.695903895904857, 'random_strength': 4.117631594624369, 'bagging_temperature': 8.322805119485638}. Best is trial 3 with value: 23.99222426021838.\n",
            "[I 2024-12-14 13:43:09,765] Trial 19 finished with value: 24.883673550630505 and parameters: {'iterations': 1708, 'depth': 4, 'learning_rate': 0.00046877382451812583, 'l2_leaf_reg': 1.132665018879666, 'random_strength': 6.229716241132149, 'bagging_temperature': 3.136779794531696}. Best is trial 3 with value: 23.99222426021838.\n",
            "[I 2024-12-14 13:43:25,842] Trial 20 finished with value: 24.632550667559286 and parameters: {'iterations': 2236, 'depth': 7, 'learning_rate': 0.003837200919187996, 'l2_leaf_reg': 7.355106356185635, 'random_strength': 8.810920012213908, 'bagging_temperature': 6.068266230263225}. Best is trial 3 with value: 23.99222426021838.\n",
            "[I 2024-12-14 13:43:27,283] Trial 21 finished with value: 24.159445628894186 and parameters: {'iterations': 1909, 'depth': 4, 'learning_rate': 0.11399387513781103, 'l2_leaf_reg': 4.5871110460416356, 'random_strength': 8.90927062839378, 'bagging_temperature': 7.89434645682763}. Best is trial 3 with value: 23.99222426021838.\n",
            "[I 2024-12-14 13:43:30,545] Trial 22 finished with value: 24.08595486430123 and parameters: {'iterations': 1870, 'depth': 5, 'learning_rate': 0.10350592749247285, 'l2_leaf_reg': 4.931661883510754, 'random_strength': 9.388634539578677, 'bagging_temperature': 9.99102932802145}. Best is trial 3 with value: 23.99222426021838.\n",
            "[I 2024-12-14 13:43:31,746] Trial 23 pruned. \n",
            "[I 2024-12-14 13:43:32,617] Trial 24 pruned. \n",
            "[I 2024-12-14 13:43:34,649] Trial 25 finished with value: 24.324454885676662 and parameters: {'iterations': 2216, 'depth': 5, 'learning_rate': 0.06376423231446877, 'l2_leaf_reg': 7.862097128895562, 'random_strength': 8.445286091559456, 'bagging_temperature': 8.726249054021103}. Best is trial 3 with value: 23.99222426021838.\n",
            "[I 2024-12-14 13:43:35,718] Trial 26 pruned. \n",
            "[I 2024-12-14 13:43:37,492] Trial 27 finished with value: 24.424627501552077 and parameters: {'iterations': 2547, 'depth': 5, 'learning_rate': 0.1520199304021661, 'l2_leaf_reg': 4.41465631407185, 'random_strength': 7.142433947934505, 'bagging_temperature': 7.3667557930856455}. Best is trial 3 with value: 23.99222426021838.\n",
            "[I 2024-12-14 13:43:40,459] Trial 28 pruned. \n",
            "[I 2024-12-14 13:43:55,762] Trial 29 finished with value: 24.695920962008444 and parameters: {'iterations': 2786, 'depth': 7, 'learning_rate': 0.004213399048241723, 'l2_leaf_reg': 12.072392417197197, 'random_strength': 6.925777177379051, 'bagging_temperature': 8.926895152440373}. Best is trial 3 with value: 23.99222426021838.\n",
            "[I 2024-12-14 13:43:57,681] Trial 30 finished with value: 24.16637492624129 and parameters: {'iterations': 2062, 'depth': 4, 'learning_rate': 0.08425388826326376, 'l2_leaf_reg': 1.6234187582422384, 'random_strength': 9.244925681753625, 'bagging_temperature': 7.615489319170171}. Best is trial 3 with value: 23.99222426021838.\n",
            "[I 2024-12-14 13:44:00,093] Trial 31 finished with value: 24.191766347461353 and parameters: {'iterations': 1841, 'depth': 4, 'learning_rate': 0.1379082588282735, 'l2_leaf_reg': 3.9433448957438006, 'random_strength': 8.41149932393582, 'bagging_temperature': 8.65276318651133}. Best is trial 3 with value: 23.99222426021838.\n",
            "[I 2024-12-14 13:44:01,264] Trial 32 pruned. \n",
            "[I 2024-12-14 13:44:01,969] Trial 33 pruned. \n",
            "[I 2024-12-14 13:44:02,642] Trial 34 pruned. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params for KMB (CatBoost): {'iterations': 1885, 'depth': 4, 'learning_rate': 0.26298936571642795, 'l2_leaf_reg': 9.66174493373097, 'random_strength': 8.311084465525061, 'bagging_temperature': 8.331085499117034}\n",
            "Best RMSE for KMB: 23.99222426021838\n",
            "Best R² for KMB: 0.0852550690596962\n",
            "Best MAPE for KMB: 3254772602751.0796\n",
            "Completed CatBoost for KMB. Forecast Return: 0.2288%\n",
            "Saved CatBoost parameters, forecasts, and performance data for KMB.\n",
            "\n",
            "Processing CatBoost model for stock: KKR\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-12-14 13:44:08,093] A new study created in RDB with name: cb_study_KKR\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new CatBoost study for KKR.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-12-14 13:45:02,024] Trial 0 finished with value: 96.87394810523658 and parameters: {'iterations': 2388, 'depth': 9, 'learning_rate': 0.00037344534506932633, 'l2_leaf_reg': 11.47319755530783, 'random_strength': 3.3009254807640054, 'bagging_temperature': 4.903974248552938}. Best is trial 0 with value: 96.87394810523658.\n",
            "[I 2024-12-14 13:47:48,882] Trial 1 finished with value: 96.83798289052004 and parameters: {'iterations': 1212, 'depth': 11, 'learning_rate': 0.00031585659721952177, 'l2_leaf_reg': 6.912800775630496, 'random_strength': 3.4189508043609838, 'bagging_temperature': 1.0030336299623166}. Best is trial 1 with value: 96.83798289052004.\n",
            "[I 2024-12-14 13:47:51,293] Trial 2 finished with value: 97.03442133565802 and parameters: {'iterations': 654, 'depth': 6, 'learning_rate': 0.0006663626159451626, 'l2_leaf_reg': 1.6194322967306418, 'random_strength': 5.6989603496178125, 'bagging_temperature': 5.838071960908772}. Best is trial 1 with value: 96.83798289052004.\n",
            "[I 2024-12-14 13:47:53,057] Trial 3 finished with value: 101.44143282043298 and parameters: {'iterations': 1947, 'depth': 5, 'learning_rate': 0.22650371548170942, 'l2_leaf_reg': 6.2961674782233565, 'random_strength': 2.542394526791858, 'bagging_temperature': 2.393699792976667}. Best is trial 1 with value: 96.83798289052004.\n",
            "[I 2024-12-14 13:47:58,313] Trial 4 finished with value: 96.73002621608293 and parameters: {'iterations': 2942, 'depth': 7, 'learning_rate': 0.011486120975163255, 'l2_leaf_reg': 11.529732468879232, 'random_strength': 6.295076297474949, 'bagging_temperature': 4.44882458167994}. Best is trial 4 with value: 96.73002621608293.\n",
            "[I 2024-12-14 13:47:59,769] Trial 5 pruned. \n",
            "[I 2024-12-14 13:48:01,072] Trial 6 pruned. \n",
            "[I 2024-12-14 13:48:01,927] Trial 7 pruned. \n",
            "[I 2024-12-14 13:48:13,594] Trial 8 pruned. \n",
            "[I 2024-12-14 13:48:17,448] Trial 9 finished with value: 96.83626649645514 and parameters: {'iterations': 2837, 'depth': 7, 'learning_rate': 0.015713820074181636, 'l2_leaf_reg': 11.862942607057951, 'random_strength': 6.025777180518574, 'bagging_temperature': 2.5718022807677112}. Best is trial 4 with value: 96.73002621608293.\n"
          ]
        }
      ],
      "source": [
        "# %% [markdown]\n",
        "# # 9. Hyperparameter Tuning and Model Training\n",
        "#\n",
        "# Train CatBoost models for each stock using Optuna for hyperparameter tuning. Calculate R² and MAPE for each model, and ensure that progress is saved persistently.\n",
        "\n",
        "# %%\n",
        "# Define the number of trials for Optuna\n",
        "N_TRIALS_CB = 35  # Adjust based on required accuracy and available computation time\n",
        "\n",
        "# Initialize a dictionary to store best parameters\n",
        "if os.path.exists(BEST_PARAMS_PATH):\n",
        "    with open(BEST_PARAMS_PATH, 'rb') as f:\n",
        "        best_params_dict = pickle.load(f)\n",
        "else:\n",
        "    best_params_dict = {}\n",
        "\n",
        "# Initialize a dictionary to store forecasts\n",
        "if os.path.exists(FORECASTS_PATH):\n",
        "    with open(FORECASTS_PATH, 'rb') as f:\n",
        "        stock_forecasts = pickle.load(f)\n",
        "else:\n",
        "    stock_forecasts = {}\n",
        "\n",
        "# Initialize a list to store model performance\n",
        "if os.path.exists(PERFORMANCE_PATH):\n",
        "    with open(PERFORMANCE_PATH, 'rb') as f:\n",
        "        model_performance = pickle.load(f)\n",
        "else:\n",
        "    model_performance = []\n",
        "\n",
        "# Iterate through each stock to train models\n",
        "for ticker in stock_data:\n",
        "    # Skip if the stock has already been processed\n",
        "    if ticker in stock_forecasts and 'CatBoost' in stock_forecasts[ticker]:\n",
        "        print(f\"Skipping CatBoost for {ticker} as it has already been processed.\")\n",
        "        continue\n",
        "\n",
        "    print(f\"\\nProcessing CatBoost model for stock: {ticker}\")\n",
        "    df = stock_data[ticker]\n",
        "\n",
        "    # Define features and target\n",
        "    X_stock = df[feature_cols]\n",
        "    y_stock = df['Target_Return']\n",
        "    w_stock = sample_weights[:len(X_stock)]  # Assuming sample_weights are aligned\n",
        "\n",
        "    # Define study name and storage\n",
        "    study_name = f\"cb_study_{ticker}\"\n",
        "    storage_name = f\"sqlite:///{STUDIES_DIR}/cb_study_{ticker}.db\"\n",
        "\n",
        "    # Check if the study already exists\n",
        "    if study_exists(study_name, storage_name):\n",
        "        study = optuna.load_study(study_name=study_name, storage=storage_name)\n",
        "        print(f\"Loaded existing CatBoost study for {ticker}.\")\n",
        "    else:\n",
        "        study = optuna.create_study(direction='minimize', study_name=study_name, storage=storage_name, load_if_exists=True, pruner=MedianPruner())\n",
        "        print(f\"Created new CatBoost study for {ticker}.\")\n",
        "\n",
        "    # Define the objective function within the loop to capture current X and y\n",
        "    def objective_cb(trial, X=X_stock, y=y_stock, w=w_stock):\n",
        "        param = {\n",
        "            'iterations': trial.suggest_int('iterations', 500, 3000),\n",
        "            'depth': trial.suggest_int('depth', 4, 12),\n",
        "            'learning_rate': trial.suggest_float('learning_rate', 1e-4, 0.3, log=True),\n",
        "            'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1, 15),\n",
        "            'random_strength': trial.suggest_float('random_strength', 1, 10),\n",
        "            'bagging_temperature': trial.suggest_float('bagging_temperature', 0, 10),\n",
        "            'od_wait': 50,\n",
        "            'random_seed': 42,\n",
        "            'loss_function': 'RMSE',\n",
        "            'verbose': False\n",
        "        }\n",
        "\n",
        "        model = CatBoostRegressor(**param)\n",
        "        tscv = TimeSeriesSplit(n_splits=3)  # Reduced splits for faster tuning\n",
        "\n",
        "        mse_scores = []\n",
        "        r2_scores = []\n",
        "        all_preds = []\n",
        "        all_true = []\n",
        "\n",
        "        for i, (train_index, test_index) in enumerate(tscv.split(X)):\n",
        "            X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[test_index]\n",
        "            y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[test_index]\n",
        "            w_train_fold, w_val_fold = w[train_index], w[test_index]\n",
        "\n",
        "            # Create Pool with sample weights\n",
        "            train_pool = Pool(X_train_fold, y_train_fold, weight=w_train_fold)\n",
        "\n",
        "            model.fit(train_pool, eval_set=(X_val_fold, y_val_fold), early_stopping_rounds=100, use_best_model=True)\n",
        "            preds = model.predict(X_val_fold)\n",
        "            mse = mean_squared_error(y_val_fold, preds)\n",
        "            r2 = r2_score(y_val_fold, preds)\n",
        "            mse_scores.append(mse)\n",
        "            r2_scores.append(r2)\n",
        "            all_preds.extend(preds)\n",
        "            all_true.extend(y_val_fold)\n",
        "\n",
        "            # Report intermediate objective value\n",
        "            trial.report(mse, i+1)\n",
        "\n",
        "            # Prune trial if not promising\n",
        "            if trial.should_prune():\n",
        "                raise TrialPruned()\n",
        "\n",
        "        # Store the average R² and MAPE as user attributes\n",
        "        trial.set_user_attr(\"r2\", np.mean(r2_scores))\n",
        "        trial.set_user_attr(\"mape\", mean_absolute_percentage_error(all_true, all_preds))\n",
        "        trial.set_user_attr(\"preds\", all_preds)\n",
        "        trial.set_user_attr(\"true\", all_true)\n",
        "\n",
        "        return np.mean(mse_scores)\n",
        "\n",
        "    try:\n",
        "        # Optimize hyperparameters using Optuna\n",
        "        study.optimize(objective_cb, n_trials=N_TRIALS_CB, timeout=1800)  # 30 minutes timeout\n",
        "\n",
        "        best_params = study.best_params\n",
        "        print(f\"Best params for {ticker} (CatBoost): {best_params}\")\n",
        "\n",
        "        # Retrieve the best trial\n",
        "        best_trial = study.best_trial\n",
        "\n",
        "        # Store best RMSE, R², and MAPE\n",
        "        model_performance.append({\n",
        "            'Stock': ticker,\n",
        "            'Model': 'CatBoost',\n",
        "            'RMSE': best_trial.value,  # Mean MSE across folds\n",
        "            'R2': best_trial.user_attrs.get(\"r2\", None),\n",
        "            'MAPE': best_trial.user_attrs.get(\"mape\", None)\n",
        "        })\n",
        "\n",
        "        print(f\"Best RMSE for {ticker}: {best_trial.value}\")\n",
        "        print(f\"Best R² for {ticker}: {best_trial.user_attrs.get('r2', None)}\")\n",
        "        print(f\"Best MAPE for {ticker}: {best_trial.user_attrs.get('mape', None)}\")\n",
        "\n",
        "        # Save best parameters\n",
        "        best_params_dict.setdefault(ticker, {})\n",
        "        best_params_dict[ticker]['CatBoost'] = best_params\n",
        "\n",
        "        # Train the best model on the entire dataset\n",
        "        best_model = CatBoostRegressor(**best_params, loss_function='RMSE', random_seed=42, verbose=False)\n",
        "        train_pool_full = Pool(X_stock, y_stock, weight=w_stock)\n",
        "        best_model.fit(train_pool_full, eval_set=(X_stock, y_stock), use_best_model=True)\n",
        "\n",
        "        # Forecasting: Predict the Target_Return on the last day\n",
        "        latest_features = df[feature_cols].iloc[-1].values.reshape(1, -1)\n",
        "        forecast_return = best_model.predict(latest_features)[0]\n",
        "\n",
        "        # Store the forecast\n",
        "        stock_forecasts.setdefault(ticker, {})\n",
        "        stock_forecasts[ticker]['CatBoost'] = forecast_return\n",
        "\n",
        "        print(f\"Completed CatBoost for {ticker}. Forecast Return: {forecast_return:.4f}%\")\n",
        "\n",
        "    except TrialPruned:\n",
        "        print(f\"CatBoost trial for {ticker} was pruned.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while processing CatBoost for {ticker}: {e}\")\n",
        "\n",
        "    # Save the best parameters after each stock\n",
        "    with open(BEST_PARAMS_PATH, 'wb') as f:\n",
        "        pickle.dump(best_params_dict, f)\n",
        "\n",
        "    # Save the forecasts and performance after each stock\n",
        "    with open(FORECASTS_PATH, 'wb') as f:\n",
        "        pickle.dump(stock_forecasts, f)\n",
        "\n",
        "    with open(PERFORMANCE_PATH, 'wb') as f:\n",
        "        pickle.dump(model_performance, f)\n",
        "\n",
        "    print(f\"Saved CatBoost parameters, forecasts, and performance data for {ticker}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMl0wPh0et7t"
      },
      "outputs": [],
      "source": [
        "# %% [markdown]\n",
        "# # 10. Calculate Investment Profits and Allocate Funds\n",
        "#\n",
        "# Calculate expected profits based on model forecasts and allocate investment funds accordingly. Ensure that only adequate stocks are considered.\n",
        "\n",
        "# %%\n",
        "# Identify adequate and inadequate stocks based on performance data\n",
        "all_stocks = list(stock_data.keys())\n",
        "\n",
        "adequate_stocks = []\n",
        "inadequate_stocks = []\n",
        "\n",
        "for stock in all_stocks:\n",
        "    # Check if the stock has a forecast and RMSE\n",
        "    if stock in stock_forecasts and 'CatBoost' in stock_forecasts[stock]:\n",
        "        # Further check if RMSE and R2 are not None (indicating successful processing)\n",
        "        performance = next((item for item in model_performance if item['Stock'] == stock and item['Model'] == 'CatBoost'), None)\n",
        "        if performance and performance['RMSE'] is not None and performance['R2'] is not None:\n",
        "            adequate_stocks.append(stock)\n",
        "        else:\n",
        "            inadequate_stocks.append(stock)\n",
        "    else:\n",
        "        inadequate_stocks.append(stock)\n",
        "\n",
        "print(f\"Total Stocks: {len(all_stocks)}\")\n",
        "print(f\"Number of Adequate Stocks: {len(adequate_stocks)}\")\n",
        "print(f\"Number of Inadequate Stocks: {len(inadequate_stocks)}\")\n",
        "print(\"\\nList of Inadequate Stocks:\")\n",
        "print(inadequate_stocks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYI2GDbbgUyd"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "# Initialize a list to store profit calculations\n",
        "profit_list = []\n",
        "\n",
        "for stock in adequate_stocks:\n",
        "    try:\n",
        "        # Retrieve the forecasted return\n",
        "        forecast_return = stock_forecasts[stock]['CatBoost']\n",
        "\n",
        "        # Get the current Close price (last available in the DataFrame)\n",
        "        current_price = stock_data[stock]['Day_Close_Price'].iloc[-1]\n",
        "\n",
        "        # Calculate the expected return in GBP\n",
        "        expected_profit = (forecast_return / 100) * current_price\n",
        "\n",
        "        # Append a dictionary to the list\n",
        "        profit_list.append({\n",
        "            'Stock': stock,\n",
        "            'Current_Price': round(current_price, 2),\n",
        "            'Forecasted_Return': round(forecast_return, 2),\n",
        "            'Expected_Profit': round(expected_profit, 2)\n",
        "        })\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing stock {stock}: {e}\")\n",
        "        # Optionally, log the error or mark the stock as inadequate\n",
        "        inadequate_stocks.append(stock)\n",
        "\n",
        "# Convert the list of dictionaries to a DataFrame\n",
        "profit_df = pd.DataFrame(profit_list)\n",
        "\n",
        "# Sort the DataFrame by Expected Profit in descending order (higher profit is better)\n",
        "profit_df.sort_values(by='Expected_Profit', ascending=False, inplace=True)\n",
        "\n",
        "# Reset index\n",
        "profit_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Display the profit DataFrame\n",
        "profit_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VzgHbPKBgXNY"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "# Total Investment\n",
        "total_investment = 30.0  # in GBP\n",
        "\n",
        "# Calculate the total expected profit of all adequate stocks\n",
        "total_expected_profit = profit_df['Expected_Profit'].sum()\n",
        "\n",
        "# Calculate the weight (allocation percentage) for each stock based on its expected profit\n",
        "# Since higher Expected_Profit is better, allocate more to stocks with higher Expected_Profit\n",
        "# Normalize Expected_Profit to sum to 1 for allocation\n",
        "if total_expected_profit == 0:\n",
        "    profit_df['Weight'] = 1 / len(profit_df)\n",
        "else:\n",
        "    profit_df['Weight'] = profit_df['Expected_Profit'] / total_expected_profit\n",
        "\n",
        "# Calculate the investment allocation for each stock\n",
        "profit_df['Investment'] = profit_df['Weight'] * total_investment\n",
        "\n",
        "# Calculate the number of shares for each stock\n",
        "profit_df['Number_of_Shares'] = profit_df['Investment'] / profit_df['Current_Price']\n",
        "\n",
        "# Calculate the expected profit for the allocated investment\n",
        "profit_df['Allocated_Profit'] = profit_df['Number_of_Shares'] * (profit_df['Forecasted_Return'])\n",
        "\n",
        "# Round the numerical columns for better readability\n",
        "profit_df[['Investment', 'Number_of_Shares', 'Allocated_Profit']] = profit_df[['Investment', 'Number_of_Shares', 'Allocated_Profit']].round(2)\n",
        "\n",
        "# Display the updated DataFrame with allocations\n",
        "profit_df[['Stock', 'Current_Price', 'Forecasted_Return', 'Expected_Profit', 'Investment', 'Number_of_Shares', 'Allocated_Profit']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRTEz4kGgZbK"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "# Final Ranked List with Investment Strategy\n",
        "final_ranking = profit_df[['Stock', 'Current_Price', 'Forecasted_Return', 'Expected_Profit', 'Investment', 'Number_of_Shares', 'Allocated_Profit']].copy()\n",
        "\n",
        "# Calculate the total allocated investment and total expected profit\n",
        "total_allocated_investment = final_ranking['Investment'].sum()\n",
        "total_allocated_profit = final_ranking['Allocated_Profit'].sum()\n",
        "\n",
        "# Display the final ranking\n",
        "print(\"Final Ranked List of Stocks Based on Expected Profit:\")\n",
        "display(final_ranking)\n",
        "\n",
        "print(f\"Total Allocated Investment: £{round(total_allocated_investment, 2)}\")\n",
        "print(f\"Total Expected Profit: £{round(total_allocated_profit, 2)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_TIcJw2_gck2"
      },
      "outputs": [],
      "source": [
        "# %% [markdown]\n",
        "# # 11. Display Inadequate Stocks\n",
        "#\n",
        "# Show a list of stocks that were excluded from the analysis due to the absence of `FinalScore` or failed model evaluations.\n",
        "\n",
        "# %%\n",
        "# Display Inadequate Stocks\n",
        "if inadequate_stocks:\n",
        "    inadequate_df = pd.DataFrame({'Inadequate Stocks': inadequate_stocks})\n",
        "    print(\"List of Inadequate Stocks (Excluded from Analysis):\")\n",
        "    display(inadequate_df)\n",
        "else:\n",
        "    print(\"No Inadequate Stocks found.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5mVd_fDdgfF8"
      },
      "outputs": [],
      "source": [
        "# %% [markdown]\n",
        "# # 12. Summary of Investment Strategy\n",
        "#\n",
        "# Provide a summarized view of the investment strategy, including total investment, expected profit, portfolio allocation, and a list of excluded stocks.\n",
        "\n",
        "# %%\n",
        "# Summary\n",
        "print(\"### Investment Strategy Summary ###\\n\")\n",
        "\n",
        "print(f\"**Total Investment Available:** £{total_investment}\\n\")\n",
        "print(f\"**Total Expected Profit:** £{round(total_allocated_profit, 2)}\\n\")\n",
        "print(\"**Portfolio Allocation:**\")\n",
        "display(final_ranking[['Stock', 'Investment', 'Number_of_Shares', 'Allocated_Profit']])\n",
        "\n",
        "if inadequate_stocks:\n",
        "    print(\"\\n**Inadequate Stocks (Excluded from Portfolio):**\")\n",
        "    display(inadequate_df)\n",
        "else:\n",
        "    print(\"\\n**All stocks were adequate for the analysis.**\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vcrGPG6lghij"
      },
      "outputs": [],
      "source": [
        "# %% [markdown]\n",
        "# # 13. Visualize R² and MAPE Scores\n",
        "#\n",
        "# Create visualizations to understand the distribution and relationship between R² and MAPE scores across all models.\n",
        "\n",
        "# %%\n",
        "# Distribution of R² Scores\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.histplot(performance_df['R2'].dropna(), bins=30, kde=True, color='skyblue')\n",
        "plt.title('Distribution of R² Scores for CatBoost Models')\n",
        "plt.xlabel('R² Score')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n",
        "\n",
        "# Distribution of MAPE\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.histplot(performance_df['MAPE'].dropna(), bins=30, kde=True, color='salmon')\n",
        "plt.title('Distribution of MAPE for CatBoost Models')\n",
        "plt.xlabel('MAPE (%)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n",
        "\n",
        "# Scatter Plot of R² vs MAPE\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.scatterplot(data=performance_df, x='R2', y='MAPE', hue='R2', palette='coolwarm', alpha=0.7)\n",
        "plt.title('R² vs MAPE for CatBoost Models')\n",
        "plt.xlabel('R² Score')\n",
        "plt.ylabel('MAPE (%)')\n",
        "plt.legend(title='R²')\n",
        "plt.show()\n",
        "\n",
        "# Boxplots for R² and MAPE\n",
        "plt.figure(figsize=(14,6))\n",
        "\n",
        "# Boxplot for R²\n",
        "plt.subplot(1,2,1)\n",
        "sns.boxplot(y=performance_df['R2'], color='lightblue')\n",
        "plt.title('Boxplot of R² Scores')\n",
        "plt.ylabel('R² Score')\n",
        "\n",
        "# Boxplot for MAPE\n",
        "plt.subplot(1,2,2)\n",
        "sns.boxplot(y=performance_df['MAPE'], color='lightgreen')\n",
        "plt.title('Boxplot of MAPE')\n",
        "plt.ylabel('MAPE (%)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Summary Statistics for R² and MAPE\n",
        "print(\"### Summary Statistics ###\\n\")\n",
        "print(performance_df[['R2', 'MAPE']].describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZouZ5tEgjzn"
      },
      "outputs": [],
      "source": [
        "# %% [markdown]\n",
        "# # 14. Plot Predicted vs. Actual Returns for Top Performing Stocks\n",
        "#\n",
        "# Visualize the accuracy of your models by plotting predicted vs. actual returns for top-performing stocks based on R² scores.\n",
        "\n",
        "# %%\n",
        "# Select top-performing stocks based on R²\n",
        "TOP_N_STOCKS = 5  # Adjust as needed\n",
        "top_performing_stocks = performance_df.sort_values(by='R2', ascending=False).head(TOP_N_STOCKS)['Stock'].tolist()\n",
        "print(f\"Top Performing Stocks based on R²: {top_performing_stocks}\")\n",
        "\n",
        "# Plot Predicted vs Actual for top-performing stocks\n",
        "for stock in top_performing_stocks:\n",
        "    # Load the corresponding study\n",
        "    study_name = f\"cb_study_{stock}\"\n",
        "    storage_name = f\"sqlite:///{STUDIES_DIR}/cb_study_{stock}.db\"\n",
        "    study_db_path = os.path.join(DATA_PATH, 'optuna_studies', f\"cb_study_{stock}.db\")\n",
        "\n",
        "    if not os.path.exists(study_db_path):\n",
        "        print(f\"Study database for {stock} not found. Skipping plot.\")\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        study = optuna.load_study(study_name=study_name, storage=storage_name)\n",
        "        best_trial = study.best_trial\n",
        "        preds = best_trial.user_attrs.get(\"preds\", [])\n",
        "        true = best_trial.user_attrs.get(\"true\", [])\n",
        "\n",
        "        if preds and true:\n",
        "            plt.figure(figsize=(8,6))\n",
        "            sns.scatterplot(x=true, y=preds, alpha=0.6)\n",
        "            plt.plot([min(true), max(true)], [min(true), max(true)], 'r--')  # Diagonal line\n",
        "            plt.title(f'Predicted vs. Actual Returns for {stock}')\n",
        "            plt.xlabel('Actual Returns (%)')\n",
        "            plt.ylabel('Predicted Returns (%)')\n",
        "            plt.show()\n",
        "        else:\n",
        "            print(f\"Predictions or true values not found for {stock}. Skipping plot.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading study for {stock}: {e}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMGIc3Akmug2kdnbTExLEP4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}